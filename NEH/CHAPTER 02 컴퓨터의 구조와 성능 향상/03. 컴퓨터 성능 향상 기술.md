# 컴퓨터 성능 향상 기술

CPU 내부 버스의 속도가 시스템 버스의 속도보다 빠르기 때문에 발생하는 속도 차이를 개선하기 위한 기술이다.

<br>



## 버퍼

### 버퍼의 개념

버퍼는 속도에 차이가 있는 두 장치 사이에서 그 차이를 완화하는 역할을 한다. 데이터 전송 속도가 느린 경우 데이터를 모았다가 한 번에 전송하면 속도를 개선할 수 있다. 이렇게 일정량의 데이터를 모아 옮김으로써 속도의 차이를 완화하는 장치가 버퍼이다.

<br>



### 스풀

스풀(SPOOL; Simultaneous Peripheral Operation On-Line)은 CPU와 입출력장치가 독립적으로 작동하도록 고안된 소프트웨어적인 버퍼이다. 대표적으로는 프린터에 사용되는 스풀러가 있다. 스풀러는 인쇄할 내용을 순차적으로 출력하는 소프트웨어로, 출력 명령을 내린 프로그램과 독립적으로 동작한다.

버퍼의 경우 어떤 프로그램이 사용하는 데이터든 버퍼가 차면 이동이 시작된다. 버퍼를 공유하는 것이다. 반면 스풀러는 한 인쇄물이 완료될 때까지 다른 인쇄물이 끼어들 수 없으므로 프로그램 간에 배타적이다.

<br>



### :pencil2: 하드웨어 안전 제거

버퍼를 사용하는 경우 버퍼가 다 채워질 때까지 저장장치 간에 데이터 전송이 지연된다. 이 타이밍에 하드웨어를 제거하는 경우 데이터가 제대로 저장되지 않을 수 있다. 이때 하드웨어 안전 제거 기능을 이용하면 버퍼에 있는 아직 옮겨지지 않은 데이터를 저장장치로 내보내고 저장장치의 전원을 차단하여 안전하게 제거할 수 있도록 한다. 유닉스의 경우 버퍼의 내용을 강제로 전송하는 명령어로 fflush를 사용한다.

<br>



## 캐시

### 캐시의 개념

캐시는 메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해 두는 임시 저장소이다. 필요한 데이터를 모아 한꺼번에 전달하는 버퍼의 일종으로 CPU가 앞으로 사용할 것으로 예상되는 데이터를 미리 가져오기(prefetch) 한다.

캐시는 CPU 안에 있으며 CPU 내부 버스의 속도로 작동한다. 따라서 느리게 작동하는 메모리와 빠르게 작동하는 CPU 사이에서 속도 차이를 완화한다. 

CPU는 메모리에 접근해야 할 경우 캐시에 먼저 방문하여 원하는 데이터가 있는지 찾아본다. 캐시에서 원하는 데이터를 찾은 경우 캐시 히트라고 하며 그 데이터를 바로 사용한다. 원하는 데이터가 없는 경우 메모리로 가서 데이터를 찾는데 이를 캐시 미스라고 한다. 캐시 히트가 되는 비율을 캐시 적중률이라고 하며, 일반적인 컴퓨터의 캐시 적중률은 약 90%이다.

컴퓨터의 성능을 향상하려면 캐시 적중률이 높아야 하고, 캐시 적중률을 높이는 방법 중 하나는 캐시의 크기를 늘리는 것이다. 캐시의 크기가 커지면 더 많은 데이터를 미리 가져올 수 있어 캐시 적중률이 올라간다. 

캐시 적중률을 높이는 또 다른 방법은 앞으로 많이 사용될 데이터를 가져오는 것이다. 이와 관련된 이론으로는 현재 위치에 가까운 데이터가 멀리 있는 데이터보다 사용될 확률이 더 높다는 지역성(locality) 이론이 있다. 지역성 이론에 따르면 goto 문을 사용하는 경우 미리 가져온 데이터가 쓸모없어지기 때문에 사용하지 않는 것이 좋다.

<br>



### 즉시 쓰기와 지연 쓰기

캐시에 있는 데이터가 변경되는 경우 이를 메모리에 반영하는 방식은 다음 두 가지가 있다.

- 즉시 쓰기 : 캐시에 있는 데이터가 변경되면 이를 즉시 메모리에 반영하는 방식이다. 메모리와의 빈번한 데이터 전송으로 인해 성능이 저하된다는 것이 단점이나, 항상 메모리에 정보가 최신으로 유지되기 때문에 갑작스러운 정전에도 데이터를 잃어버리지 않는 장점이 있다.
- 지연 쓰기 : 캐시에 있는 데이터가 변경되면 변경된 내용을 모아서 주기적으로 반영하는 방식으로 카피백이라고도 한다. 메모리와의 데이터 전송 횟수가 줄어 시스템의 성능을 향상할 수 있으나, 메모리와 캐시된 데이터 사이에 불일치가 발생할 수 있다는 단점이 있다.

<br>



### L1 캐시와 L2 캐시

- L1 캐시 : CPU 레지스터에 직접 연결된 캐시 (명령어 캐시, 데이터 캐시)
- L2 캐시 : 메모리와 연결된 일반 캐시

<br>

#### :pencil2: 웹 브라우저 캐시

소프트웨어적으로 사용되는 캐시의 대표적 예이다. 다시 방문할 것을 예상하여 지우지 않은 데이터라고 정의할 수 있으며 주로 로고나 버튼 등을 캐시에 보관하고 있다가 사이트를 다시 방문하면 캐시에 있는 데이터를 사용하여 속도를 높인다. 하지만 너무 많은 데이터가 캐시에 저장되어 있는 경우 웹 브라우저의 속도를 떨어트릴 수 있다.

<br>



## 저장 장치의 계층 구조

가격과 컴퓨터 성능 사이의 타협점으로 저장장치의 계층 구조가 존재한다. 저장장치의 계층 구조는 속도가 빠르고 값이 비싼 저장장치를 CPU 가까운 쪽에 두고, 값이 싸고 용량이 큰 저장장치를 반대쪽에 배치하여 적당한 가격으로 빠른 속도와 큰 용량을 동시에 얻는 방법이다.

저장장치의 계층 구조의 문제점은 중복되는 데이터의 일관성을 유지하는 것이다. CPU가 캐시에 저장된 데이터를 변경하면 메모리의 해당 주소에 있는 데이터도 갱신되어야 하는데, 지연 쓰기를 하는 경우 문제가 된다. 또한 협업 중인 다른 작업에서 해당 데이터를 읽으려 한다면 일관성이 깨질 수 있다. 버퍼를 사용하는 하드디스크 같은 저장장치에서도 데이터의 일관성이 깨질 수 있다.

<br>



## 인터럽트

### 인터럽트의 개념

초기의 컴퓨터 시스템에는 주변장치가 많지 않아 CPU가 직접 입출력장치에서 데이터를 가져오거나 봐냈는데 이 방식을 풀링 방식이라고 한다. 풀링 방식에서는 CPU가 입출력 장치의 상태를 주기적으로 검사하여 일정한 조건을 만족할 때 데이터를 처리한다. CPU가 명령어 해석과 실행이라는 본래 역할 외에 모든 입출력까지 관여하기 때문에 작업 효율이 떨어진다.

오늘날의 컴퓨터에는 많은 주변장치가 있기 때문에 풀링 방식을 이용하면 작업 효율이 매우 떨어진다. 이 문제를 해결하기 위해 등장한 방식이 인터럽트 방식으로 CPU의 작업과 저장장치의 데이터 이동을 독립적으로 운영한다. 따라서 데이터의 입출력이 이루어지는 동안 CPU가 다른 작업을 할 수 있다.

<br>



### 인터럽트 방식의 동작 과정

1. CPU가 입출력 관리자에게 입출력 명령을 보낸다.
2. 입출력 관리자는 명령받은 데이터를 메모리에 가져다 놓거나 메모리에 있는 데이터를 저장장치로 옮긴다.
3. 데이터 전송이 완료되면 입출력 관리자는 완료 신호를 CPU에 보낸다.

위 동작 과정에서 입출력 관리자가 CPU에 보내는 완료 신호를 인터럽트라고 한다. CPU는 완료 신호를 받으면 하던 일을 중단하고 옮겨진 데이터를 처리한다.

인터럽트 방식에서는 많은 주변장치 중 어떤 것의 작업이 끝났는지를 CPU에 알려 주기 위해 인터럽트 번호를 사용한다. 인터럽트 번호는 완료 신호를 보낼 때 장치의 이름 대신 사용하는 장치의 고유 번호로 운영체제마다 다르다. 윈도우 운영체제의 경우 인터럽트 번호를 IRQ라고 부르며 키보드의 IRQ는 1번, 마우스의 IRQ는 12번, 첫 번째 하드디스크의 IRQ는 14번과 같이 구분해서 사용한다.

CPU는 입출력 관리자에게 여러 개의 입출력 작업을 동시에 시킬 수 있다. 이 경우 여러 작업이 동시에 완료될 수 있는데, 그때마다 인터럽트를 여러 번 사용하면 매우 비효율적이다. 따라서 여러 개의 인터럽트를 하나의 배열로 만든 인터럽트 벡터를 사용한다. CPU가 인터럽트 벡터를 받으면 완료된 인터럽트를 동시에 처리한다.

입출력 작업이 완료된 것을 CPU에 알리는 것 외에도 다양한 종류의 인터럽트가 존재한다.

<br>



### 직접 메모리 접근

입출력 관리자가 CPU의 명령을 받으면 CPU가 요청한 데이터를 메모리에 가져다 놓아야 한다. 하지만 메모리는 CPU만 접근 권한을 가지고 있기 때문에 메모리에 접근할 수 있는 권한이 필요하다. 이러한 권한을 직접 메모리 접근(DMA)이라고 한다. 데이터 전송을 지시받은 입출력 관리자는 직접 메모리 접근 권한이 있어야 CPU의 관여 없이 작업을 완료할 수 있다.

<br>



### 메모리 매핑 입출력

직접 메모리 접근은 인터럽트 방식의 시스템을 구성하는 게 필수 요소이나, 직접 메모리 접근을 사용하면 메모리가 복잡해진다. 직접 메모리 접근을 통해 들어온 데이터를 메모리에 아무렇게나 두는 경우 CPU가 사용하는 데이터와 섞여서 관리하기 어렵기 때문에 이를 막기 위해 메모리를 나누어 사용하는 방법이 도입되었다. CPU가 사용하는 메모리 공간과 직접 메모리 접근을 통해 들어오거나 나가는 데이터를 위한 공간을 분리하는 것이다. 이렇게 메모리의 일정 공간을 입출력에 할당하는 기법을 메모리 매핑 입출력이라고 한다.

<br>



### 사이클 훔치기

CPU와 입출력 장치가 동시에 메모리에 접근하는 경우 보통은 CPU가 메모리 사용 권한을 양보한다. CPU의 작업 속도보다 입출력장치의 속도가 느리기 때문에 양보하는 것으로 이러한 상황을 사이클 훔치기라고 부른다.













